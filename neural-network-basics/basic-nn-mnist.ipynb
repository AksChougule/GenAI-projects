{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a168c2c",
   "metadata": {},
   "source": [
    "Description:Creating NN using torch and understanding steps involved\n",
    "\n",
    "Dataset: MNIST\n",
    "\n",
    "Credits: [Tutorial by Nick Ochanack](https://github.com/nicknochnack/PyTorchin15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fae47b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import torch \n",
    "from PIL import Image\n",
    "from torch import nn, save, load\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b17d0f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9912422/9912422 [00:00<00:00, 21181168.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 28881/28881 [00:00<00:00, 57274559.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1648877/1648877 [00:00<00:00, 18598355.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4542/4542 [00:00<00:00, 10756933.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get data \n",
    "train = datasets.MNIST(root=\"data\", download=True, train=True, transform=ToTensor())\n",
    "dataset = DataLoader(train, 32)\n",
    "#1,28,28 - classes 0-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89d390b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Classifier Neural Network\n",
    "class ImageClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Define the layers of the neural network using nn.Sequential\n",
    "        self.model = nn.Sequential(\n",
    "            # First convolutional layer: input channels=1, output channels=32, kernel size=(3,3)\n",
    "            nn.Conv2d(1, 32, (3, 3)),\n",
    "            nn.ReLU(),  # ReLU activation function\n",
    "            # Second convolutional layer: input channels=32, output channels=64, kernel size=(3,3)\n",
    "            nn.Conv2d(32, 64, (3, 3)),\n",
    "            nn.ReLU(),  # ReLU activation function\n",
    "            # Third convolutional layer: input channels=64, output channels=64, kernel size=(3,3)\n",
    "            nn.Conv2d(64, 64, (3, 3)),\n",
    "            nn.ReLU(),  # ReLU activation function\n",
    "            nn.Flatten(),  # Flatten the output to a 1D tensor\n",
    "            # Fully connected layer: input size=64*(28-6)*(28-6), output size=10\n",
    "            nn.Linear(64 * (28 - 6) * (28 - 6), 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Define the forward pass of the neural network\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d02913",
   "metadata": {},
   "source": [
    "Here's a summary of each part:\n",
    "\n",
    "### Constructor (__init__) Method:\n",
    "- Initializes the ImageClassifier class by inheriting from nn.Module.\n",
    "- Defines a sequential model (self.model) that consists of convolutional layers, ReLU activation functions, and a fully connected layer.\n",
    "\n",
    "### Sequential Model (self.model):\n",
    "Convolutional Layers:\n",
    "- The first convolutional layer has 1 input channel (assumed to be grayscale images), produces 32 output channels, and uses a 3x3 kernel.\n",
    "- The second convolutional layer takes 32 input channels, produces 64 output channels, and uses a 3x3 kernel.\n",
    "- The third convolutional layer takes 64 input channels, produces 64 output channels, and uses a 3x3 kernel.\n",
    "\n",
    "ReLU Activation Functions:\n",
    "- Rectified Linear Unit (ReLU) activation functions follow each convolutional layer.\n",
    "\n",
    "Flatten Layer:\n",
    "- Flattens the output of the convolutional layers into a 1D tensor.\n",
    "\n",
    "Fully Connected Layer:\n",
    "- A fully connected layer (linear layer) takes the flattened input with a size calculated based on the output shape of the last convolutional layer and produces an output of size 10. This is common for classification tasks where you have 10 classes.\n",
    "\n",
    "### Forward Method (forward):\n",
    "- Defines the forward pass of the neural network by applying the layers defined in the constructor (self.model) to the input tensor x.\n",
    "\n",
    "This code assumes input images of size 28x28 pixels (MNIST-like), and it's designed for a classification task with 10 output classes. The specific architecture and hyperparameters can be adjusted based on the requirements of the task at hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "333311d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instance of the neural network, loss, optimizer \n",
    "clf = ImageClassifier().to('cuda')\n",
    "opt = Adam(clf.parameters(), lr=1e-3)\n",
    "loss_fn = nn.CrossEntropyLoss() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41231db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0 loss is 0.020670462399721146\n",
      "Epoch:1 loss is 0.0012369464384391904\n",
      "Epoch:2 loss is 0.0040187956765294075\n",
      "Epoch:3 loss is 3.8196114473976195e-05\n",
      "Epoch:4 loss is 0.00019526893447618932\n",
      "Epoch:5 loss is 2.0104871509829536e-05\n",
      "Epoch:6 loss is 8.828911290947872e-07\n",
      "Epoch:7 loss is 3.0397582122532185e-06\n",
      "Epoch:8 loss is 8.940689610881236e-08\n",
      "Epoch:9 loss is 6.444721520892926e-07\n",
      "tensor(9, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Training loop for 10 epochs\n",
    "    for epoch in range(10):\n",
    "        for batch in dataset:\n",
    "            X, y = batch\n",
    "            X, y = X.to('cuda'), y.to('cuda')\n",
    "            yhat = clf(X)  # Forward pass\n",
    "            loss = loss_fn(yhat, y)\n",
    "\n",
    "            # Apply backpropagation\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "        print(f\"Epoch:{epoch} loss is {loss.item()}\")\n",
    "\n",
    "    # Save the trained model\n",
    "    with open('model_state.pt', 'wb') as f:\n",
    "        save(clf.state_dict(), f)\n",
    "\n",
    "    # Load the saved model\n",
    "    with open('model_state.pt', 'rb') as f:\n",
    "        clf.load_state_dict(load(f))\n",
    "\n",
    "    # Load an image and make a prediction\n",
    "    img = Image.open('img_3.jpg')\n",
    "    img_tensor = ToTensor()(img).unsqueeze(0).to('cuda')\n",
    "\n",
    "    # Make a prediction on the image\n",
    "    print(torch.argmax(clf(img_tensor)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a04cd9",
   "metadata": {},
   "source": [
    "Training Loop:\n",
    "- The code iterates through 10 epochs, where each epoch processes batches of data from the dataset.\n",
    "- For each batch, it performs a forward pass (clf(X)) to get predictions, calculates the loss using loss_fn, and then performs backpropagation and optimization using the opt optimizer.\n",
    "\n",
    "Print Epoch Loss:\n",
    "- After each epoch, it prints the epoch number and the corresponding loss.\n",
    "\n",
    "Save Model:\n",
    "- It saves the state dictionary of the trained model (clf.state_dict()) to a file named 'model_state.pt'.\n",
    "\n",
    "Load Model:\n",
    "- It loads the saved model state back into the clf model.\n",
    "\n",
    "Make Prediction on an Image:\n",
    "- It loads an image ('img_3.jpg'), converts it to a PyTorch tensor using ToTensor(), adds a batch dimension with unsqueeze(0), and moves it to the GPU ('cuda').\n",
    "- It then makes a prediction using the trained model (clf) and prints the index of the maximum value in the prediction tensor (argmax), which corresponds to the predicted class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8c6de9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "img = Image.open('img_1.jpg') \n",
    "img_tensor = ToTensor()(img).unsqueeze(0).to('cuda')\n",
    "\n",
    "print(torch.argmax(clf(img_tensor)))"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
